# Pron√≥stico H√≠brido Espacio-Temporal de Precipitaciones en Chile: Integrando Aprendizaje Profundo, Geoestad√≠stica y Teledetecci√≥n

Chile presenta una fuerte variabilidad espacio-temporal de precipitaciones, lo que impacta la gesti√≥n h√≠drica, la agricultura y la planificaci√≥n territorial. Los modelos num√©ricos tradicionales tienen dificultades para representar las correlaciones espaciales y las dependencias no lineales que caracterizan el clima chileno.

Este proyecto propone un modelo h√≠brido de pron√≥stico espacio-temporal de precipitaciones, integrando tres pilares metodol√≥gicos:

1. **Aprendizaje profundo** mediante Autoencoders y **Descomposici√≥n Modal Din√°mica (DMD)** para extraer patrones latentes y predecir su evoluci√≥n temporal.

3. **El operador de Koopman**, incorporado mediante el enfoque **KoVAE**, que permite representar din√°micas no lineales de forma lineal en el espacio latente, mejorando la capacidad predictiva y probabil√≠stica.

4. **Geoestad√≠stica y teledetecci√≥n**, empleando t√©cnicas de kriging y co-kriging junto con datos satelitales (CHIRPS, GPM y MODIS) para generar mallas continuas y coherentes espacialmente.

# Pregunta de investigaci√≥n:

¬øPuede la integraci√≥n de aprendizaje profundo, geoestad√≠stica y teledetecci√≥n mejorar la precisi√≥n y coherencia espacial del pron√≥stico de precipitaciones en Chile respecto al AE + DMD tradicional?

# Hip√≥tesis:

La combinaci√≥n del operador de Koopman con Autoencoders, junto a la interpolaci√≥n geoestad√≠stica de alta resoluci√≥n y datos sat√©lite, permitir√° modelar mejor las correlaciones espacio-temporales y reducir el error de predicci√≥n a nivel local y regional.

**Impacto potencial:**

Los resultados apoyar√°n la planificaci√≥n h√≠drica y la gesti√≥n del riesgo clim√°tico, entregando mapas predictivos de precipitaci√≥n para Chile. Este proyecto pretende validar√° la aplicaci√≥n pr√°ctica del modelo en cuencas hidrogr√°ficas prioritarias en zonas de sequias.

-----------

# 2. Revisi√≥n de literatura / Estado del arte

La predicci√≥n de variables clim√°ticas ha evolucionado desde m√©todos estad√≠sticos lineales (ARIMA, SARIMA, VAR, PROPHET) hacia modelos de Deep Learning y enfoques h√≠bridos, capaces de capturar relaciones no lineales y multiescalares.

**Trabajos previos UDD ‚Äì Herrera (2023-2024):**

Marchant & Silva (2024) demostraron la eficacia del enfoque Autoencoder + DMD para pronosticar precipitaciones locales, obteniendo mejoras de precisi√≥n superiores al 80 % respecto al modelo DeepAR, con costos computacionales bajos.

P√©rez & Zavala (2023) aplicaron EOFs + Deep Learning a datos ERA5, destacando la utilidad de la reducci√≥n de dimensionalidad mediante SVD para representar patrones clim√°ticos dominantes.

**Literatura internacional:**

Amato et al. (2020) propusieron un marco de predicci√≥n espaciotemporal basado en Deep Learning aplicado a variables ambientales.

Lusch et al. (2018) y Kutz et al. (2016) desarrollaron la DMD como t√©cnica data-driven para sistemas din√°micos complejos.

Lam et al. (2023) y Wong (2023) evidenciaron el potencial del AI aplicado a la predicci√≥n meteorol√≥gica global (GraphCast, DeepMind Weather).

Cressie & Wikle (2011) fundamentaron la geoestad√≠stica espaciotemporal como marco probabil√≠stico para modelar dependencias espaciales.

---

## Glosario de Conceptos T√©cnicos

### **Autoencoder (AE)**
Red neuronal no supervisada que comprime datos (encoder) y los reconstruye (decoder). Usado para capturar patrones espaciales de precipitaci√≥n en representaci√≥n compacta.

### **Espacio Latente**
Representaci√≥n de menor dimensi√≥n (ej: 64-dim) de datos originales (6437 celdas). Reduce complejidad preservando informaci√≥n esencial.

### **DMD (Descomposici√≥n Modal Din√°mica)**
T√©cnica data-driven que descompone sistemas din√°micos en modos espacio-temporales coherentes. Extrae patrones + frecuencias para pron√≥sticos.

### **KoVAE (Koopman Variational Autoencoder)**
Extensi√≥n probabil√≠stica del Autoencoder que usa el Operador de Koopman para representar din√°micas no lineales como lineales. Incluye incertidumbre.

### **Variograma**
Funci√≥n que cuantifica correlaci√≥n espacial vs distancia. Par√°metros: nugget (error), sill (varianza m√°x), range (alcance correlaci√≥n).

### **Kriging**
Interpolaci√≥n geoestad√≠stica √≥ptima que genera campos continuos + varianza de estimaci√≥n a partir de observaciones puntuales.

### **Dilated Convolutions**
Convoluciones con "huecos" que expanden campo receptivo sin aumentar par√°metros. Captura contexto multi-escala.

### **M√©tricas**
- **MAE**: Error promedio absoluto (mm/d√≠a)
- **RMSE**: Ra√≠z error cuadr√°tico medio
- **NSE**: Eficiencia Nash-Sutcliffe (hidrolog√≠a)
- **Skill Score**: Mejora % vs baseline

---

## Estructura del Proyecto

**Estructura actualizada del proyecto Capstone**:

```
CAPSTONE_PROJECT/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # Datos originales ERA5 descargados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ precipitation_data.npy
‚îÇ   ‚îú‚îÄ‚îÄ processed/                # Datos procesados y normalizados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ era5_precipitation_chile_full.nc    # NetCDF ERA5 2020 (366 d√≠as, 157√ó41)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variogram_parameters_june_2020.csv  # Par√°metros geoestad√≠sticos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kriging_precipitation_june_2020.nc  # Interpolaci√≥n kriging
‚îÇ   ‚îî‚îÄ‚îÄ models/                   # Modelos entrenados
‚îÇ       ‚îú‚îÄ‚îÄ autoencoder_geostat.h5              # Autoencoder completo
‚îÇ       ‚îú‚îÄ‚îÄ encoder_geostat.h5                  # Solo encoder
‚îÇ       ‚îî‚îÄ‚îÄ training_metrics.csv                # Historial entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb                            # ‚úÖ EDA b√°sico
‚îÇ   ‚îú‚îÄ‚îÄ 01A_Eda_spatiotemporal.ipynb           # ‚úÖ EDA espacial-temporal (macrozonas)
‚îÇ   ‚îú‚îÄ‚îÄ 02_DL_DMD_Forecast.ipynb               # üìö Ejemplo Prof. Herrera (did√°ctico)
‚îÇ   ‚îú‚îÄ‚îÄ 02_Geoestadistica_Variogramas_Kriging.ipynb  # ‚úÖ Variogramas y kriging
‚îÇ   ‚îú‚îÄ‚îÄ 03_AE_DMD_Training.ipynb               # ‚úÖ Entrenamiento AE+DMD baseline
‚îÇ   ‚îú‚îÄ‚îÄ 04_Advanced_Metrics.ipynb              # ‚úÖ M√©tricas avanzadas (NSE, SS)
‚îÇ   ‚îú‚îÄ‚îÄ 04_KoVAE_Test.ipynb                    # ‚è≥ KoVAE (preparado, no ejecutado)
‚îÇ   ‚îú‚îÄ‚îÄ 05_Hyperparameter_Experiments.ipynb    # ‚úÖ Optimizaci√≥n 13 configs
‚îÇ   ‚îî‚îÄ‚îÄ 06_DMD_Interpretability.ipynb          # ‚úÖ Interpretabilidad DMD (modos f√≠sicos)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ae_dmd.py                           # Modelo AE+DMD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ae_keras.py                         # Arquitectura autoencoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kovae.py                            # KoVAE (futuro)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ download_era5.py                    # Descarga desde Copernicus CDS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ merge_era5.py                       # Concatenaci√≥n NetCDF
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ merge_era5_advanced.py              # Procesamiento avanzado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py                      # Carga de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                          # MAE, RMSE, NSE
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlflow_utils.py                     # Utilidades MLflow
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ train_ae_dmd.py                         # Script entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ figures/                                # Visualizaciones generadas
‚îÇ       ‚îú‚îÄ‚îÄ ae_dmd_spatial_weights.png
‚îÇ       ‚îú‚îÄ‚îÄ ae_training_curves.png
‚îÇ       ‚îú‚îÄ‚îÄ ae_reconstruction_examples.png
‚îÇ       ‚îú‚îÄ‚îÄ hyperparameter_analysis.png         # Optimizaci√≥n hiperpar√°metros
‚îÇ       ‚îú‚îÄ‚îÄ dmd_eigenvalues_complex_plane.png   # Eigenvalores DMD
‚îÇ       ‚îú‚îÄ‚îÄ dmd_spatial_modes_decoded.png       # Top 5 modos decodificados
‚îÇ       ‚îî‚îÄ‚îÄ dmd_energy_by_zone.png              # Energ√≠a por macrozona
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                                     # Tracking MLflow (temporal deshabilitado)
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ ROADMAP.md                                  # Hoja de ruta actualizada
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ conda.yaml
‚îî‚îÄ‚îÄ MLproject
```

## Instrucciones de Uso

### 1. Configuraci√≥n del Entorno

Crear entorno Conda con Python 3.10.13:

```bash
conda env create -f conda.yaml
conda activate capstone
```

Instalar TensorFlow con soporte GPU (NVIDIA):

```bash
# Instalar TensorFlow GPU
pip install tensorflow-gpu==2.10.0

# Instalar CUDA Toolkit y cuDNN
conda install cudatoolkit=11.2 cudnn=8.1 -c conda-forge -y
```

Verificar GPU detectada:

```bash
python -c "import tensorflow as tf; print('GPUs:', tf.config.list_physical_devices('GPU'))"
```

### 2. Descarga de Datos ERA5 desde Copernicus

**Pipeline completo implementado** para descargar precipitaciones horarias de ERA5:

```bash
# Paso 1: Descargar desde Copernicus Climate Data Store
# Requiere cuenta en https://cds.climate.copernicus.eu/
# Configurar credenciales en ~/.cdsapirc
python src/utils/download_era5.py

# Paso 2: Concatenar archivos NetCDF mensuales
python src/utils/merge_era5.py

# Paso 3: Procesar (horaria‚Üídiaria, subset Chile, validaci√≥n)
python src/utils/merge_era5_advanced.py
```

**Salida**: `data/processed/era5_precipitation_chile_full.nc` (366 d√≠as, 157√ó41 grid, 0.25¬∞ resoluci√≥n)

### 3. An√°lisis Exploratorio y Geoestad√≠stica

Ejecutar notebooks en orden:

```bash
jupyter notebook notebooks/
```

1. `01_EDA.ipynb` - EDA b√°sico
2. `01A_Eda_spatiotemporal.ipynb` - An√°lisis por macrozonas Norte/Centro/Sur
3. `02_Geoestadistica.ipynb` - Variogramas, kriging, pesos espaciales
4. `03_AE_DMD_Training.ipynb` - **Entrenamiento actual AE-DMD con GPU**

### 4. Entrenamiento del Modelo

El notebook `03_AE_DMD_Training.ipynb` ejecuta el pipeline completo:

- Carga datos ERA5 2020 normalizados
- Construye arquitectura CNN informada por geoestad√≠stica (receptive field ~8.23¬∞)
- Loss ponderado espacialmente por varianza kriging
- Entrenamiento con GPU (NVIDIA RTX A4000): ~56 segundos
- Evaluaci√≥n de reconstrucci√≥n en test set

**Resultados actuales**:
- Train loss: 0.015, Val loss: 0.031 (weighted MSE)
- Test MAE: 0.319, RMSE: 0.642 (datos normalizados)

## Documentaci√≥n T√©cnica Actualizada

### Pipeline de Datos ERA5

**Scripts de descarga y procesamiento** (`src/utils/`):

1. **`download_era5.py`**: 
   - Conexi√≥n a Copernicus CDS API
   - Descarga precipitaci√≥n horaria (`total_precipitation`)
   - Regi√≥n: Chile (-76¬∞ a -66¬∞ lon, -56¬∞ a -17¬∞ lat)
   - Periodo: 2020 completo (366 d√≠as)
   - Resoluci√≥n: 0.25¬∞ (~27.5 km)
   - Requiere credenciales CDS en `~/.cdsapirc`

2. **`merge_era5.py`**: 
   - Concatena archivos NetCDF mensuales
   - Dimensiones temporales coherentes
   - Validaci√≥n de fechas continuas

3. **`merge_era5_advanced.py`**: 
   - Agregaci√≥n horaria ‚Üí diaria (sum)
   - Subset espacial exacto Chile
   - Conversi√≥n m ‚Üí mm
   - Validaci√≥n calidad (NaNs, rango ‚â•0)
   - Output: `era5_precipitation_chile_full.nc` (tiempo=366, lat=157, lon=41)

### Geoestad√≠stica Implementada

**An√°lisis variogr√°fico** (`notebooks/02_Geoestadistica.ipynb`):

- C√°lculo de variogramas experimentales (junio 2020)
- Ajuste de modelos: spherical, exponential, gaussian
- **Mejor ajuste (spherical)**: range=8.23¬∞, sill=23.45, nugget‚âà0
- Ordinary Kriging con PyKrige (malla 391√ó101)
- Varianza kriging usada para **pesos espaciales** en loss function
- Validaci√≥n leave-one-out cross-validation

### Arquitectura del Autoencoder

**Dise√±o informado por variogramas** (`03_AE_DMD_Training.ipynb`):

- **Encoder**: Dilated CNN (dilations=[1,2,4,8])
  - Receptive field ~40 celdas (cumple range 8.23¬∞ del variograma)
  - MaxPooling 2√ó2 (3 capas) ‚Üí compresi√≥n espacial
  - Bottleneck: 64-dim latent space
  
- **Decoder**: Conv2DTranspose sim√©trico
  - UpSampling 2√ó2 (3 capas)
  - Cropping exacto para output (157, 41, 1)
  
- **Loss function**: Weighted MSE
  - Pesos = 1 / (varianza_kriging + Œµ)
  - Penaliza m√°s errores en zonas de alta confianza

- **Regularizaci√≥n**: L2 = 0.0001 (nugget‚âà0 ‚Üí datos limpios)

### Entrenamiento y Evaluaci√≥n

**Hardware**: NVIDIA RTX A4000 (16GB VRAM)
**Software**: TensorFlow 2.10 + CUDA 11.2 + cuDNN 8.1

**Splits**:
- Train: 251 sequences (70%)
- Validation: 53 sequences (15%)
- Test: 55 sequences (15%)

**Hiperpar√°metros**:
- Epochs: 100 (early stopping patience=15)
- Batch size: 16
- Optimizer: Adam (lr=0.001)
- ReduceLROnPlateau: factor=0.5, patience=7

**Resultados** (datos normalizados):
- Train loss: 0.015, Val loss: 0.031
- Test MSE: 0.412, MAE: 0.319, RMSE: 0.642
- Tiempo entrenamiento: ~56 segundos (con GPU)

**Optimizaci√≥n de Hiperpar√°metros** (`05_Hyperparameter_Experiments.ipynb`):
- 13 configuraciones evaluadas (latent_dim, SVD rank, dilations, epochs)
- **Mejor configuraci√≥n**: Dilations [1,3,9,27] + Latent 64
- **MAE final**: 1.934 mm/d√≠a (17.3% mejora sobre baseline 2.339 mm/d√≠a)
- Todos los modos DMD 100% estables (|Œª|‚â§1)
- Tiempo total: ~5 minutos (13 experimentos)

**Interpretabilidad DMD** (`06_DMD_Interpretability.ipynb`):
- DMD entrenado en espacio latente: **23 modos**, 100% estables
- Top 5 modos decodificados de latent (64-dim) ‚Üí espacio f√≠sico (157√ó41)
- **An√°lisis por macrozonas**:
  - Centro: Mayor energ√≠a en modo #1 (0.382)
  - Norte: Balance distribuido modos #2-5 (0.330-0.355)
  - Sur: Energ√≠a uniforme moderada (0.280-0.340)
- **Per√≠odos identificados**: Mayor√≠a de muy baja frecuencia (>60 d√≠as o estacionarios)
- **Visualizaciones temporales**: Serie temporal punto individual (Centro Chile), comparaci√≥n 3 macrozonas (Norte/Centro/Sur), evoluci√≥n componentes latentes DMD (10 dimensiones, 15 pasos)
- Figuras generadas: 6 figuras (eigenvalues, spatial modes, energy zones, temporal evolution point, temporal zones, latent evolution)
- Resultados guardados: `dmd_interpretability_results.pkl` (128 KB)

### Pr√≥ximos Pasos (Opcionales)

Ver `ROADMAP.md` para tareas pendientes:

1. ‚úÖ ~~**DMD en espacio latente**~~ - Completado (23 modos, 100% estables)
2. ‚úÖ ~~**Desnormalizaci√≥n**~~ - M√©tricas en mm/d√≠a reales
3. ‚úÖ ~~**An√°lisis por macrozonas**~~ - Norte/Centro/Sur evaluados
4. ‚úÖ ~~**Baselines**~~ - Persistencia y climatolog√≠a implementados
5. ‚úÖ ~~**Optimizaci√≥n hiperpar√°metros**~~ - 13 configs, MAE 1.934 mm/d√≠a
6. ‚úÖ ~~**Interpretabilidad DMD**~~ - Modos decodificados a espacio f√≠sico
7. **Validaci√≥n CHIRPS** - Comparar con datos satelitales (opcional)
8. **KoVAE** - Implementar operador de Koopman variacional (opcional)
9. **Resolver MLflow** - Conflicto protobuf (MLflow 3.6 vs TF 2.10)

---

## Referencias y Metadatos

**√öltima actualizaci√≥n**: 19 noviembre 2025  
**Responsable**: C√©sar Godoy Delaigue  
**Fase actual**: Fase 2 - Implementaci√≥n AE-DMD (**Completada 95%**)
**Notebooks ejecutados**: 6/8 (75% implementaci√≥n + 25% extensiones opcionales)

### Stack Tecnol√≥gico Confirmado

- **Datos**: xarray, netCDF4, pandas, numpy
- **Descarga**: cdsapi (Copernicus Climate Data Store)
- **Geoestad√≠stica**: PyKrige, scikit-gstat, scipy
- **ML/DL**: TensorFlow 2.10 (GPU), Keras, scikit-learn
- **DMD**: PyDMD (pendiente implementaci√≥n)
- **Visualizaci√≥n**: matplotlib, seaborn, cartopy
- **Experimentaci√≥n**: MLflow (temporal deshabilitado)
- **Infraestructura**: Conda, Git, GitHub, CUDA 11.2, cuDNN 8.1

### Referencias Clave

1. **Marchant & Silva (2024)** - AE+DMD para precipitaciones Chile (UDD)
2. **P√©rez & Zavala (2023)** - EOFs + Deep Learning ERA5 (UDD)
3. **Lusch et al. (2018)** - Deep learning for universal linear embeddings
4. **Kutz et al. (2016)** - Dynamic Mode Decomposition
5. **Cressie & Wikle (2011)** - Statistics of Spatio-Temporal Data
6. **ERA5 Documentation** - ECMWF Reanalysis v5

### Contacto y Soporte

- **Repositorio**: https://github.com/Godoca2/Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile
- **Issues**: GitHub Issues para reportar problemas
- **Documentaci√≥n**: Ver `ROADMAP.md` para hoja de ruta detallada

