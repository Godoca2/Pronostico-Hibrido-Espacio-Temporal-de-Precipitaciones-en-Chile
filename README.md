# PronÃ³stico HÃ­brido Espacio-Temporal de Precipitaciones en Chile: Integrando Aprendizaje Profundo, GeoestadÃ­stica y TeledetecciÃ³n

Chile presenta una fuerte variabilidad espacio-temporal de precipitaciones, lo que impacta la gestiÃ³n hÃ­drica, la agricultura y la planificaciÃ³n territorial. Los modelos numÃ©ricos tradicionales tienen dificultades para representar las correlaciones espaciales y las dependencias no lineales que caracterizan el clima chileno.

Este proyecto propone un modelo hÃ­brido de pronÃ³stico espacio-temporal de precipitaciones, integrando tres pilares metodolÃ³gicos:

1. **Aprendizaje profundo** mediante Autoencoders y **DescomposiciÃ³n Modal DinÃ¡mica (DMD)** para extraer patrones latentes y predecir su evoluciÃ³n temporal.

3. **El operador de Koopman**, incorporado mediante el enfoque **KoVAE**, que permite representar dinÃ¡micas no lineales de forma lineal en el espacio latente, mejorando la capacidad predictiva y probabilÃ­stica.

4. **GeoestadÃ­stica y teledetecciÃ³n**, empleando tÃ©cnicas de kriging y co-kriging junto con datos satelitales (CHIRPS, GPM y MODIS) para generar mallas continuas y coherentes espacialmente.

# Pregunta de investigaciÃ³n:

Â¿Puede la integraciÃ³n de aprendizaje profundo, geoestadÃ­stica y teledetecciÃ³n mejorar la precisiÃ³n y coherencia espacial del pronÃ³stico de precipitaciones en Chile respecto al AE + DMD tradicional?

# HipÃ³tesis:

La combinaciÃ³n del operador de Koopman con Autoencoders, junto a la interpolaciÃ³n geoestadÃ­stica de alta resoluciÃ³n y datos satÃ©lite, permitirÃ¡ modelar mejor las correlaciones espacio-temporales y reducir el error de predicciÃ³n a nivel local y regional.

**Impacto potencial:**

Los resultados apoyarÃ¡n la planificaciÃ³n hÃ­drica y la gestiÃ³n del riesgo climÃ¡tico, entregando mapas predictivos de precipitaciÃ³n para Chile. Este proyecto pretende validarÃ¡ la aplicaciÃ³n prÃ¡ctica del modelo en cuencas hidrogrÃ¡ficas prioritarias en zonas de sequias.

-----------

# 2. RevisiÃ³n de literatura / Estado del arte

La predicciÃ³n de variables climÃ¡ticas ha evolucionado desde mÃ©todos estadÃ­sticos lineales (ARIMA, SARIMA, VAR, PROPHET) hacia modelos de Deep Learning y enfoques hÃ­bridos, capaces de capturar relaciones no lineales y multiescalares.

**Trabajos previos UDD â€“ Herrera (2023-2024):**

Marchant & Silva (2024) demostraron la eficacia del enfoque Autoencoder + DMD para pronosticar precipitaciones locales, obteniendo mejoras de precisiÃ³n superiores al 80 % respecto al modelo DeepAR, con costos computacionales bajos.

PÃ©rez & Zavala (2023) aplicaron EOFs + Deep Learning a datos ERA5, destacando la utilidad de la reducciÃ³n de dimensionalidad mediante SVD para representar patrones climÃ¡ticos dominantes.

**Literatura internacional:**

Amato et al. (2020) propusieron un marco de predicciÃ³n espaciotemporal basado en Deep Learning aplicado a variables ambientales.

Lusch et al. (2018) y Kutz et al. (2016) desarrollaron la DMD como tÃ©cnica data-driven para sistemas dinÃ¡micos complejos.

Lam et al. (2023) y Wong (2023) evidenciaron el potencial del AI aplicado a la predicciÃ³n meteorolÃ³gica global (GraphCast, DeepMind Weather).

Cressie & Wikle (2011) fundamentaron la geoestadÃ­stica espaciotemporal como marco probabilÃ­stico para modelar dependencias espaciales.

---

## Glosario de Conceptos TÃ©cnicos

### **Autoencoder (AE)**
Red neuronal no supervisada que comprime datos (encoder) y los reconstruye (decoder). Usado para capturar patrones espaciales de precipitaciÃ³n en representaciÃ³n compacta.

### **Espacio Latente**
RepresentaciÃ³n de menor dimensiÃ³n (ej: 64-dim) de datos originales (6437 celdas). Reduce complejidad preservando informaciÃ³n esencial.

### **DMD (DescomposiciÃ³n Modal DinÃ¡mica)**
TÃ©cnica data-driven que descompone sistemas dinÃ¡micos en modos espacio-temporales coherentes. Extrae patrones + frecuencias para pronÃ³sticos.

### **KoVAE (Koopman Variational Autoencoder)**
ExtensiÃ³n probabilÃ­stica del Autoencoder que usa el Operador de Koopman para representar dinÃ¡micas no lineales como lineales. Incluye incertidumbre.

### **Variograma**
FunciÃ³n que cuantifica correlaciÃ³n espacial vs distancia. ParÃ¡metros: nugget (error), sill (varianza mÃ¡x), range (alcance correlaciÃ³n).

### **Kriging**
InterpolaciÃ³n geoestadÃ­stica Ã³ptima que genera campos continuos + varianza de estimaciÃ³n a partir de observaciones puntuales.

### **Dilated Convolutions**
Convoluciones con "huecos" que expanden campo receptivo sin aumentar parÃ¡metros. Captura contexto multi-escala.

### **MÃ©tricas**
- **MAE**: Error promedio absoluto (mm/dÃ­a)
- **RMSE**: RaÃ­z error cuadrÃ¡tico medio
- **NSE**: Eficiencia Nash-Sutcliffe (hidrologÃ­a)
- **Skill Score**: Mejora % vs baseline

---

## Estructura del Proyecto

**Estructura actualizada del proyecto Capstone**:

```
CAPSTONE_PROJECT/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Datos originales ERA5 descargados
â”‚   â”‚   â””â”€â”€ precipitation_data.npy
â”‚   â”œâ”€â”€ processed/                # Datos procesados y normalizados
â”‚   â”‚   â”œâ”€â”€ era5_precipitation_chile_full.nc    # NetCDF ERA5 2020 (366 dÃ­as, 157Ã—41)
â”‚   â”‚   â”œâ”€â”€ variogram_parameters_june_2020.csv  # ParÃ¡metros geoestadÃ­sticos
â”‚   â”‚   â””â”€â”€ kriging_precipitation_june_2020.nc  # InterpolaciÃ³n kriging
â”‚   â””â”€â”€ models/                   # Modelos entrenados
â”‚       â”œâ”€â”€ autoencoder_geostat.h5              # Autoencoder completo
â”‚       â”œâ”€â”€ encoder_geostat.h5                  # Solo encoder
â”‚       â””â”€â”€ training_metrics.csv                # Historial entrenamiento
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb                            # âœ… EDA bÃ¡sico
â”‚   â”œâ”€â”€ 01A_Eda_spatiotemporal.ipynb           # âœ… EDA espacial-temporal (macrozonas)
â”‚   â”œâ”€â”€ 02_DL_DMD_Forecast.ipynb               # ğŸ“š Ejemplo Prof. Herrera (didÃ¡ctico)
â”‚   â”œâ”€â”€ 02_Geoestadistica_Variogramas_Kriging.ipynb  # âœ… Variogramas y kriging
â”‚   â”œâ”€â”€ 03_AE_DMD_Training.ipynb               # âœ… Entrenamiento AE+DMD baseline
â”‚   â”œâ”€â”€ 04_Advanced_Metrics.ipynb              # âœ… MÃ©tricas avanzadas (NSE, SS)
â”‚   â”œâ”€â”€ 04_KoVAE_Test.ipynb                    # â³ KoVAE (preparado, no ejecutado)
â”‚   â””â”€â”€ 05_Hyperparameter_Experiments.ipynb    # âœ… OptimizaciÃ³n 13 configs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ae_dmd.py                           # Modelo AE+DMD
â”‚   â”‚   â”œâ”€â”€ ae_keras.py                         # Arquitectura autoencoder
â”‚   â”‚   â”œâ”€â”€ kovae.py                            # KoVAE (futuro)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ download_era5.py                    # Descarga desde Copernicus CDS
â”‚   â”‚   â”œâ”€â”€ merge_era5.py                       # ConcatenaciÃ³n NetCDF
â”‚   â”‚   â”œâ”€â”€ merge_era5_advanced.py              # Procesamiento avanzado
â”‚   â”‚   â”œâ”€â”€ data_loader.py                      # Carga de datos
â”‚   â”‚   â”œâ”€â”€ metrics.py                          # MAE, RMSE, NSE
â”‚   â”‚   â”œâ”€â”€ mlflow_utils.py                     # Utilidades MLflow
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_ae_dmd.py                         # Script entrenamiento
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                                # Visualizaciones generadas
â”‚       â”œâ”€â”€ ae_dmd_spatial_weights.png
â”‚       â”œâ”€â”€ ae_training_curves.png
â”‚       â””â”€â”€ ae_reconstruction_examples.png
â”‚
â”œâ”€â”€ mlruns/                                     # Tracking MLflow (temporal deshabilitado)
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ ROADMAP.md                                  # Hoja de ruta actualizada
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ conda.yaml
â””â”€â”€ MLproject
```

## Instrucciones de Uso

### 1. ConfiguraciÃ³n del Entorno

Crear entorno Conda con Python 3.10.13:

```bash
conda env create -f conda.yaml
conda activate capstone
```

Instalar TensorFlow con soporte GPU (NVIDIA):

```bash
# Instalar TensorFlow GPU
pip install tensorflow-gpu==2.10.0

# Instalar CUDA Toolkit y cuDNN
conda install cudatoolkit=11.2 cudnn=8.1 -c conda-forge -y
```

Verificar GPU detectada:

```bash
python -c "import tensorflow as tf; print('GPUs:', tf.config.list_physical_devices('GPU'))"
```

### 2. Descarga de Datos ERA5 desde Copernicus

**Pipeline completo implementado** para descargar precipitaciones horarias de ERA5:

```bash
# Paso 1: Descargar desde Copernicus Climate Data Store
# Requiere cuenta en https://cds.climate.copernicus.eu/
# Configurar credenciales en ~/.cdsapirc
python src/utils/download_era5.py

# Paso 2: Concatenar archivos NetCDF mensuales
python src/utils/merge_era5.py

# Paso 3: Procesar (horariaâ†’diaria, subset Chile, validaciÃ³n)
python src/utils/merge_era5_advanced.py
```

**Salida**: `data/processed/era5_precipitation_chile_full.nc` (366 dÃ­as, 157Ã—41 grid, 0.25Â° resoluciÃ³n)

### 3. AnÃ¡lisis Exploratorio y GeoestadÃ­stica

Ejecutar notebooks en orden:

```bash
jupyter notebook notebooks/
```

1. `01_EDA.ipynb` - EDA bÃ¡sico
2. `01A_Eda_spatiotemporal.ipynb` - AnÃ¡lisis por macrozonas Norte/Centro/Sur
3. `02_Geoestadistica.ipynb` - Variogramas, kriging, pesos espaciales
4. `03_AE_DMD_Training.ipynb` - **Entrenamiento actual AE-DMD con GPU**

### 4. Entrenamiento del Modelo

El notebook `03_AE_DMD_Training.ipynb` ejecuta el pipeline completo:

- Carga datos ERA5 2020 normalizados
- Construye arquitectura CNN informada por geoestadÃ­stica (receptive field ~8.23Â°)
- Loss ponderado espacialmente por varianza kriging
- Entrenamiento con GPU (NVIDIA RTX A4000): ~56 segundos
- EvaluaciÃ³n de reconstrucciÃ³n en test set

**Resultados actuales**:
- Train loss: 0.015, Val loss: 0.031 (weighted MSE)
- Test MAE: 0.319, RMSE: 0.642 (datos normalizados)

## DocumentaciÃ³n TÃ©cnica Actualizada

### Pipeline de Datos ERA5

**Scripts de descarga y procesamiento** (`src/utils/`):

1. **`download_era5.py`**: 
   - ConexiÃ³n a Copernicus CDS API
   - Descarga precipitaciÃ³n horaria (`total_precipitation`)
   - RegiÃ³n: Chile (-76Â° a -66Â° lon, -56Â° a -17Â° lat)
   - Periodo: 2020 completo (366 dÃ­as)
   - ResoluciÃ³n: 0.25Â° (~27.5 km)
   - Requiere credenciales CDS en `~/.cdsapirc`

2. **`merge_era5.py`**: 
   - Concatena archivos NetCDF mensuales
   - Dimensiones temporales coherentes
   - ValidaciÃ³n de fechas continuas

3. **`merge_era5_advanced.py`**: 
   - AgregaciÃ³n horaria â†’ diaria (sum)
   - Subset espacial exacto Chile
   - ConversiÃ³n m â†’ mm
   - ValidaciÃ³n calidad (NaNs, rango â‰¥0)
   - Output: `era5_precipitation_chile_full.nc` (tiempo=366, lat=157, lon=41)

### GeoestadÃ­stica Implementada

**AnÃ¡lisis variogrÃ¡fico** (`notebooks/02_Geoestadistica.ipynb`):

- CÃ¡lculo de variogramas experimentales (junio 2020)
- Ajuste de modelos: spherical, exponential, gaussian
- **Mejor ajuste (spherical)**: range=8.23Â°, sill=23.45, nuggetâ‰ˆ0
- Ordinary Kriging con PyKrige (malla 391Ã—101)
- Varianza kriging usada para **pesos espaciales** en loss function
- ValidaciÃ³n leave-one-out cross-validation

### Arquitectura del Autoencoder

**DiseÃ±o informado por variogramas** (`03_AE_DMD_Training.ipynb`):

- **Encoder**: Dilated CNN (dilations=[1,2,4,8])
  - Receptive field ~40 celdas (cumple range 8.23Â° del variograma)
  - MaxPooling 2Ã—2 (3 capas) â†’ compresiÃ³n espacial
  - Bottleneck: 64-dim latent space
  
- **Decoder**: Conv2DTranspose simÃ©trico
  - UpSampling 2Ã—2 (3 capas)
  - Cropping exacto para output (157, 41, 1)
  
- **Loss function**: Weighted MSE
  - Pesos = 1 / (varianza_kriging + Îµ)
  - Penaliza mÃ¡s errores en zonas de alta confianza

- **RegularizaciÃ³n**: L2 = 0.0001 (nuggetâ‰ˆ0 â†’ datos limpios)

### Entrenamiento y EvaluaciÃ³n

**Hardware**: NVIDIA RTX A4000 (16GB VRAM)
**Software**: TensorFlow 2.10 + CUDA 11.2 + cuDNN 8.1

**Splits**:
- Train: 251 sequences (70%)
- Validation: 53 sequences (15%)
- Test: 55 sequences (15%)

**HiperparÃ¡metros**:
- Epochs: 100 (early stopping patience=15)
- Batch size: 16
- Optimizer: Adam (lr=0.001)
- ReduceLROnPlateau: factor=0.5, patience=7

**Resultados** (datos normalizados):
- Train loss: 0.015, Val loss: 0.031
- Test MSE: 0.412, MAE: 0.319, RMSE: 0.642
- Tiempo entrenamiento: ~56 segundos (con GPU)

### PrÃ³ximos Pasos

Ver `ROADMAP.md` para tareas pendientes:

1. **DMD en espacio latente** - Aplicar PyDMD sobre embeddings 64-dim
2. **DesnormalizaciÃ³n** - Convertir mÃ©tricas a mm/dÃ­a reales
3. **AnÃ¡lisis por macrozonas** - Evaluar Norte/Centro/Sur separadamente
4. **Baselines** - Comparar con persistencia y climatologÃ­a
5. **KoVAE** - Implementar operador de Koopman (Fase 3)
6. **Resolver MLflow** - Conflicto protobuf (MLflow 3.6 vs TF 2.10)

---

## Referencias y Metadatos

**Ãšltima actualizaciÃ³n**: 19 noviembre 2025  
**Responsable**: CÃ©sar Godoy Delaigue  
**Fase actual**: Fase 2 - ImplementaciÃ³n AE-DMD (En Progreso)

### Stack TecnolÃ³gico Confirmado

- **Datos**: xarray, netCDF4, pandas, numpy
- **Descarga**: cdsapi (Copernicus Climate Data Store)
- **GeoestadÃ­stica**: PyKrige, scikit-gstat, scipy
- **ML/DL**: TensorFlow 2.10 (GPU), Keras, scikit-learn
- **DMD**: PyDMD (pendiente implementaciÃ³n)
- **VisualizaciÃ³n**: matplotlib, seaborn, cartopy
- **ExperimentaciÃ³n**: MLflow (temporal deshabilitado)
- **Infraestructura**: Conda, Git, GitHub, CUDA 11.2, cuDNN 8.1

### Referencias Clave

1. **Marchant & Silva (2024)** - AE+DMD para precipitaciones Chile (UDD)
2. **PÃ©rez & Zavala (2023)** - EOFs + Deep Learning ERA5 (UDD)
3. **Lusch et al. (2018)** - Deep learning for universal linear embeddings
4. **Kutz et al. (2016)** - Dynamic Mode Decomposition
5. **Cressie & Wikle (2011)** - Statistics of Spatio-Temporal Data
6. **ERA5 Documentation** - ECMWF Reanalysis v5

### Contacto y Soporte

- **Repositorio**: https://github.com/Godoca2/Pronostico-Hibrido-Espacio-Temporal-de-Precipitaciones-en-Chile
- **Issues**: GitHub Issues para reportar problemas
- **DocumentaciÃ³n**: Ver `ROADMAP.md` para hoja de ruta detallada

